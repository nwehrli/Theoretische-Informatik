\documentclass[a4paper, 11pt]{article}
\usepackage[a4paper, total={7in, 10in}]{geometry}

%packages
\usepackage{kantlipsum}
\usepackage{pgfplots}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{mathtools}

% drawing automata
\usepackage{tikz}
\usetikzlibrary{arrows,automata,positioning}

% various
\usepackage{amsfonts}
\usepackage{scalerel}
\usepackage{amssymb}
\usepackage{wasysym}
\usepackage{amsmath}

% pseudocode
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{turnstile}

% Tables
\usepackage{tabularx, multirow}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{placeins}
% \renewcommand*{\arraystretch}{2}

% Make enumerations more compact
\usepackage{enumitem}
\setitemize{itemsep=0.5pt}
\setenumerate{itemsep=0.75pt}

% for centered slash through \implies and \iff
\usepackage{centernot}

% hyperlinks
\usepackage{hyperref}
\hypersetup{
    colorlinks = true,
    linkcolor = black,
    filecolor = magenta,
    urlcolor = blue,
    pdftitle = {Theoretische Informatik - Beweise 101},
    pdfpagemode = FullScreen,
}

\urlstyle{same}

%Checkboxes for multiple choice
\newlist{Checkboxes}{itemize}{2}
\setlist[Checkboxes]{label=$\square$}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\correct}{\rlap{$\square$}{\raisebox{2pt}{\hspace{1pt}\cmark}}\hspace{-2.5pt}}



%------------------------------------------------------
%Custom Commands
\def\Z{\mathbb{Z}}
\def\R{\mathbb{R}}
\def\N{\mathbb{N}}
\def\C{\mathbb{C}}
\def\L{\mathcal{L}}
\def\O{\mathcal{O}}
\def\Lre{\mathcal{L}_\text{RE}}
\def\Lr{\mathcal{L}_\text{R}}
\newcommand\comm[1]{\textcolor{red}{#1}}


% define nice looking boxes
\usepackage[many]{tcolorbox}

% a base set, that is then customised
\tcbset {
  base/.style={
    boxrule=0mm,
    boxsep = 1mm,
    leftrule=1mm,
    left=0.8mm,
    arc=2mm, 
    fonttitle=\bfseries, 
    colbacktitle=black!10!white, 
    coltitle=black, 
    toptitle=0.0mm, 
    bottomtitle=0.0mm,
    title={#1}
  }
}

\definecolor{darkred}{rgb}{0.54, 0, 0}
\newtcolorbox{mainbox}[1]{
  colframe=darkred, 
  base={#1}
}

\newtcolorbox{subbox}[1]{
  colframe=black!20!white,
  base={#1}
}



%-----------------------------------------------------

\DeclareMathOperator*{\Bigcdot}{\scalerel*{\cdot}{\bigodot}}

\setlength{\parindent}{0mm}
\setlength{\parskip}{2mm}

\pgfplotsset{samples=100}
\pgfplotsset{compat=1.18}


\newcommand\myTitle[1]{{\large \textbf {#1}}}
\newcommand\ruleSmall{\vspace{-2mm}\begin{center}\rule{0.4\linewidth}{0.3pt}\end{center}\vspace{-2mm}}
\newcommand\ruleMedium{\begin{center}\rule{0.8\linewidth}{1pt}\end{center}}


%--------------------------------------------------
% HEAD
\pagestyle{fancy}
\fancyhf{}
\setlength{\headheight}{27.5pt}
\rhead{Nicolas Wehrli}
\lhead{ETH Zürich, Autumn 2023}
% page numbering
\cfoot{\thepage}
%--------------------------------------------------

\begin{document}
    %--------------------------------------------------
    % Caption
   \begin{titlepage}
    \begin{center}
        \vspace*{5cm}
        \LARGE \textbf{Theoretische Informatik} \\ Beweise 101
    
        \small\textit{Nicolas Wehrli, ETH Zurich}

        \vspace*{5cm}
        \today
    \end{center}
   
   \end{titlepage}

   {\LARGE\textbf{Disclaimer}}

   This is a personal summary I completed during my time as a Teaching Assistant 
   for this course at ETH Zurich. It is not an official document and the content 
   is neither \textbf{complete} nor does it \textbf{guarantee} to be correct.

   I tried to give examples to accompany the theory and show some common recipes to solve certain exercises. 
   
   If you find any mistakes or inconsistencies, I would be very happy about a quick message so that I can correct them;)

   You can reach me under \href{mailto: nwehrl@student.ethz.ch}{nwehrl@student.ethz.ch} 
   and the LaTex Source code can be found \href{https://github.com/nwehrli/Theoretische-Informatik}{here}.

   The corresponding slides from my exercise session are available on a small \href{https://n.ethz.ch/~nwehrl/TheoInf}{website} of mine.
   
   Note that the summary does not cover 'Grammatiken' since this was only covered 
   after the second midterm in the autumn semester of 2023. 
   The non-deterministic hierarchical stuff (section 6.4 in the german version of the book) 
   was also not covered since the endterm preparation was prioritised.

   These parts may be added later.
   

   Hope this helps. Good luck in your future and may you achieve your goals!

   Feel free to reach out if you have any questions.
   \newpage

    %--------------------------------------------------
    %--------------------------------------------------
    %--------------------------------------------------
   \tableofcontents
    \newpage
   \input{sections/01-Grundbegriffe.tex}
   \input{sections/02-Algorithmische-Probleme.tex}
   \input{sections/03-Kolmogorov.tex}
   \input{sections/04-EA.tex}
   \input{sections/05-Nichtregularität.tex}
   \input{sections/06-NEA.tex}
   \input{sections/07-TM.tex}
   \input{sections/08-Einstieg-Berechenbarkeit.tex}
   \input{sections/09-Reduktion.tex}
   





    
       
            
                
                \section{How To Reduktion}
                
                    \subsection{$L \in \Lr$ }
                        Wir kennen zwei Methoden um dies zu beweisen:
                        \begin{enumerate}[label=\Roman*.]
                            \item \textbf{Reduktion}
                            \begin{enumerate}[label = (\alph*)]
                                \item Wir finden eine Sprache $L' \in \L_\text{R}$ (entweder schon in Vorlesung bewiesen oder selbst beweisen).
                                \item  Zeige die Reduktion $L \leq_{\text{R}} L'$ (folgt trivial aus Lemma 5.4 für $L' = L^\complement$).
                            \end{enumerate}
                                \item \textbf{Direkter Beweis: TM Konstruktion}
                                \begin{enumerate}[label=(\alph*)]
                                    \item Beschreibung einer TM (bzw. ein Algorithmus) $M$ mit $L(M) = L$. Dabei kann man eine schon bekannte TM $A$ verwenden, die immer hält (i.e. $L(A) \in \Lr$).
                                    \item Beweise $L(M) = L$ und dass die TM $M$ \textbf{immer} hält.
                                \end{enumerate}
                        \end{enumerate}
                
                
                
                    \subsection{$L \notin \Lr$}
                        Wir kennen hier auch 3 Arten:
                        \begin{itemize}[label=-]
                            \item \textbf{Trivial}
                            
                            Folgt sofort aus $L \notin \L_{\text{RE}}$, da $\L_{\text{R}} \subset \L_{\text{RE}}$.
                            \item \textbf{Reduktion}
                            \begin{enumerate}[label=(\alph*)]
                               \item Finde eine Sprache $L'$, so dass $L' \notin \L_{\text{R}}$ (muss bewiesen werden, falls nicht im Buch).
                               \item Beweise $L' \leq_{\text{R/EE}} L$.
                               \item Geeignete Sprachen als $L'$ sind: $L_{empty}^\complement, L_{diag}^\complement, L_\text{H}, L_\text{U}, L_{\text{H}, \lambda}$. (Alle im Buch bewiesen)
                            \end{enumerate}
                            \item \textbf{Satz von Rice} 
                        \end{itemize}
                
                
                \subsection{Anwendung von Satz von Rice}
                    Für den \textbf{Satz von Rice}:
                    \begin{itemize}[label=-]
                        \item Wir können mit diesem Satz nur $L \notin \L_{\text{R}}$ beweisen!
                        \item Wir haben folgende Bedingungen:
                        \begin{enumerate}[label=\roman*.]
                            \item $L \subseteq \text{KodTM}$
                            \item $\exists$ TM $M$: Kod$(M) \in L$
                            \item $\exists$ TM $M$: Kod$(M) \notin L$
                            \item $\forall$ TM $M_1, M_2$: $L(M_1) = L(M_2) \implies \left(\text{Kod}(M_1) \in L \iff \text{Kod}(M_2) \in L\right)$
                        \end{enumerate}
                        Für den letzten Punkt (4) muss man überprüfen, ob in der Definition von $L = \{\text{Kod}(M) \mid M \text{ ist TM und ...}\}$ überall nur $L(M)$ vorkommt und nirgends $M$ direkt. 
                        
                        Beziehungsweise reicht es, wenn man die Bedingung so umschreiben kann, dass sie nur noch durch $L(M)$ beschrieben ist.
                    \end{itemize}
                
                
                
                    \subsection{$L \in \L_{\text{RE}}$}
                    \begin{enumerate}[label=\Roman*.]
                        \item  Wir beschreiben eine TM $M$ mit $L(M) = L$, die nicht immer halten muss. 
                        \item  Meistens muss die TM eine Eigenschaft, für alle möglichen Wörter prüfen. 
                        \item  Bsp: $L = \{\text{Kod}(M_1) \mid \text{Kod}(M_1) \in L_\text{H}^\complement\}$: Wir gehen alle Wörter durch, um dasjenige zu finden, für das $M_1$ hält.
                        \item  Wir verwenden oft einen von den folgenden 2 Tricks, um dies zu tun:
                        \begin{itemize}[label=-]
                            \item Da es für jede NTM $M'$, eine TM $M$ gibt, so dass $L(M') = L(M)$, können wir eine solche definieren, für die $L(M') = L$ gilt.
                            \item Die andere Variante, ist die parallele Simulation von Wörtern, bei dem man das Diagonalisierungsverfahren aus dem Buch verwendet. (Bsp: Beweis $L_{\text{empty}} \in \L_{\text{RE}}$, S. 156 Buch)
                        \end{itemize}
                    \end{enumerate}
                
                    \subsection{$L \notin \L_{\text{RE}}$}
                        Hier haben wir 2 mögliche (offizielle) Methoden:
                        \begin{itemize}[label=-]
                            \item Diagonalisierungsargument mit Widerspruch, wie beim Beweis von $L_{\text{diag}} \notin \L_{\text{RE}}$.
                            \item Widerspruchsbeweis mit der Aussage $L \in \L_{\text{RE}} \land L^\complement \in \L_{\text{RE}} \implies L \in \L_{\text{R}}$ (Aufgabe 5.22, muss begründet werden!).
                        \end{itemize}
                        Inoffiziell könnten wir auch die EE-Reduktion verwenden, wird aber weder in der Vorlesung noch im Buch erwähnt.
                    
                
                
                
                    \subsection{EE- und R-Reduktionen: Tipps und Tricks}
                        \begin{itemize}[label=-]
                            \item Die vorgeschaltete TM $A$ muss immer terminieren! I.e. sie muss ein Algorithmus sein.
                            
                            \item Die Eingabe sollte immer zuerst auf die Richtige Form überprüft werden!
                            
                            Auch im Korrektsheitsbeweis, sollte dieser Fall als erstes abgehandelt werden.
                            \item EE-Reduktion: Für Korrektheit müssen wir immer $x \in L_1 \iff A(x) \in L_2$ beweisen.
                            
                            \item Wir verwenden meistens folgende 2 Tricks:
                            \begin{enumerate}[label=\roman*.]
                                \item Transitionen nach $q_{accept}$ oder $ q_{reject}$ umleiten nach $q_{reject}$/$q_{accept}$ oder einer \textbf{Endlosschleife}. 
                                \item TM $M'$ konstruieren, die ihre Eingabe ignoriert und immer dasselbe tut (z.B. eine TM dessen Kodierung gegeben ist, auf ein fixes Wort simuliern).
                            \end{enumerate}
                            
                            \item Die Kodierung einer TM generieren, dessen Sprache gewisse Eigenschaften hat(z.B. sie akzeptiert alle Eingaben, läuft immer unendlich etc.)
                            
                            \item Bei $L_1 \leq_{\text{R/EE}} L_2$ nehmen wir einen Algorithmus $A_{L_2}$ an mit $L(A_{L_2}) = L_2$. 
                            
                            Wir können $A_{L_2}$ auch in der Kodierung einer TM $M'$ verwenden, die wir dann zu $A_{L_2}$ übergeben! 
                        \end{itemize}

                        \myTitle{Fortgeschrittener Trick - oben schon gezeigt}

                            \textbf{Aufgabe}
                        
                            Sei $L_{\text{all}} = \{\text{Kod}(M) \mid M \text{ akzeptiert jede Eingabe}\}$.
                        
                            Zeigen Sie $L_{\text{H}}^\complement \leq_{\text{EE}} L_{\text{all}}$.
                            
                            
                            \textbf{Kernidee}
                        
                            Für eine Eingabe $x = \text{Kod}(M)\#w$, generieren wir Kod$(A)$ einer TM $A$, die folgendes folgendes macht:
                            
                            $\mathbf{A}(y)$:
                            \begin{enumerate}[label=\arabic*.]
                                
                                \item Berechnet $|y|$ Schritte von $M$ auf $w$.
                                
                                \item Falls danach die Berechnung nach $|y|$ noch nicht terminiert hat, akzeptiert $A$ die Eingabe $y$.
                                
                                \item Sonst verwirft $A$ die Eingabe.
                            \end{enumerate}
                            
                            \begin{center}
                                $A$ akzeptiert jede Eingabe $\iff$ $M$ läuft unendlich auf $w$
                            \end{center}
                            
                            Wir nutzen, dass $L_{\text{all}}$ unendlich viele Wörter hat, um implizit jede mögliche endliche Berechnungslänge abzudecken und eine Endlosschleife zu erkennen.
                        
                
            
                        \myTitle{Bemerkung: Implikationsbeweis für Reduktion}

                            Wenn eine Reduktion verlangt wird, dann dürft ihr die Implikation nicht trivial per Implikationsaussage zeigen.
                                
                            Gemeint damit ist folgender Ansatz. 
                        
                                $L_1 \leq_{\text{R}} L_2$ soll gezeigt werden. 
                            
                                    
                                Da per Definition 
                                $$L_1 \leq_{\text{R}} L_2 \iff (L_2 \in \Lr \implies L_1 \in \Lr)$$
                                folgt die gewünschte Aussage per $L_2 \notin \Lr$ (oder $L_1 \in \Lr$). 
                        
                                \textbf{Dieser Ansatz gibt an der Prüfung $0$ Punkte.}
                       
                        
                        \section{Komplexitätstheorie}
                        
                        \subsection{Konfiguration}

                            Wir erinneren uns:
                            \begin{mainbox}{Konfiguration einer $k$-Band-TM}
                                Die Konfiguration einer $k$-Band-TM sieht wie folgt aus
                                $$(q, w, i, u_1, i_1, u_2, i_2, ..., u_k, i_k) \in Q \times \Sigma^* \times \N \times (\Gamma^* \times \N)^k$$
                                wobei 
                                \begin{itemize}[label = $\blacktriangleright$]
                                    
                                    \item $q$ der Zustand der TM ist
                                    
                                    \item $\cent w \$$ der Inhalt des Eingabebandes, Lesekopf Eingabeband auf dem $i$-ten Feld
                                    
                                    \item für $j \in \{1, ..., k\}$ ist der Inhalt des $j$-ten Bandes $\cent u_j \text{\textvisiblespace \textvisiblespace \textvisiblespace}$ und $i_j \leq |u_j|$ die Position des Kopfs auf dem $j$-ten Band. 
                                \end{itemize}
                            \end{mainbox}
                       \subsection{Time}
                            \begin{mainbox}{}
                                Sei $M$ eine MTM oder TM, die immer hält. Sei $\Sigma$ das Eingabealphabet von $M$. 
                                Sei $x \in \Sigma^*$ und $D = C_1, C_2, ...,C_k$ die Berechnung von $M$ auf $x$.
                                
                                
                                Die \textbf{Zeitkomplexität $\mathbf{\textbf{Time}_M(x)}$ der 
                                Berechnung von $\mathbf{M}$ auf $\mathbf{x}$} ist definiert durch
                                $$\mathbf{\textbf{Time}_M(x)} = k-1.$$
                                
                                
                                Die \textbf{Zeitkomplexität von $\mathbf{M}$} ist die Funktion $\text{Time}_M: \N \to \N$, definiert durch
                                $$\mathbf{\textbf{Time}_M(n)} = \text{max}\left\{\text{Time}_M(x) \mid x \in \Sigma^n\right\}.$$
                            \end{mainbox}
                   
                        
                        \subsection{Space}
                            \begin{mainbox}{}
                                Sei $k \in \N\setminus\{0\}$. Sei $M$ eine $k$-Band-TM, die immer hält.
                        
                                Sei 
                                \begin{align*}
                                    C = (q, x, i, \alpha_1, i_1, \alpha_2, i_2, ..., \alpha_k, i_k)\\
                                    \text{mit }0 \leq i \leq |x|+1 \text{ und } 0 \leq i_j \leq |\alpha_j| \text{ für } j = 1, ..., k
                                \end{align*}
                                eine Konfiguration von $M$. 
                                
                                
                                Die \textbf{Speicherplatzkomplexität von $\mathbf{C}$} ist 
                                $$\mathbf{\textbf{Space}_M(C)} = \max\{|\alpha_i| \mid i = 1, ..., k\}.$$
                            \end{mainbox}
                     
                            \begin{mainbox}{}
                                Sei $C_1, C_2, ..., C_l$ die Berechnung von $M$ auf $x$. Die \textbf{Speicherplatzkomplexität von $\mathbf{M}$ auf $\mathbf{x}$} ist 
                                $$\mathbf{\textbf{Space}_M(x) }= \max\left\{\text{Space}_M(C_i) \mid i = 1, ..., l\right\}.$$
                                
                                Die \textbf{Speicherplatzkomplexität von $\mathbf{M}$} ist die Funktion $\text{Space}_M: \N \to \N$, definiert durch 
                                $$\mathbf{\textbf{Space}_M(n)} = \max\left\{\text{Space}_M(x) \mid x \in \Sigma^n\right\}.$$
                            \end{mainbox}
                        
                            \textbf{Bemerkungen}
                            \begin{enumerate}[label=\arabic*.]
                                \item Länge des Eingabewortes, hat keinen Einfluss auf die Speicherplatzkomplexität.
                                \item Mächtigkeit des Alphabets hat keinen Einfluss auf die Speicherplatzkomplexität.
                            \end{enumerate}
                            
                     
                            \begin{mainbox}{Lemma 6.1}
                                Sei $k \in \N\setminus\{0\}$. Für jede $k$-Band-TM $A$, die immer hält, existiert eine äquivalente $1$-Band-TM $B$, so dass 
                                $$\text{Space}_B(n) \leq \text{Space}_A(n)$$
                            \end{mainbox}
                            
                            \textbf{Beweisskizze: }
                        
                            Gleiche Konstruktion wie in Lemma 4.2.
                            
                            Lemma 4.2 = ''Für jede MTM $A$ existiert eine äquivalente TM $B$''. 
                            
                            Wir sehen, dass $B$ genau so viele Felder braucht, wie $A$.
                        
                            \begin{mainbox}{Lemma 6.2}
                                Zu jeder MTM $A$ existiert eine äquivalente MTM $B$ mit 
                                $$\text{Space}_B(n) \leq \frac{\text{Space}_A(n)}{2}+2$$
                            \end{mainbox}
                            
                            \textbf{Beweisskizze: }
                        
                            Wir fassen jeweils 2 Felder von $A$ zu einem Feld in $B$ zusammen. $\Gamma_B = \Gamma_A \times \Gamma_A$. Wir addieren $1$ für das $\cent$ am linken Rand und $1$ für das Aufrunden im Fall von ungerader Länge.
                        
                            \subsection{Asymptotik}
                            \begin{itemize}[label=$\blacktriangleright$]
                                
                                \item $\mathbf{\O(f(n))}$: 
                                
                                Menge aller Funktionen, die asymptotisch nicht schneller wachsen als $f(n)$.
                                
                                \item $\boldsymbol{\Omega}\mathbf{(g(n))}$: 
                                
                                Menge aller Funktionen, die asymptotisch mind. so schnell wachsen wie $g(n)$.
                                
                                \item $\boldsymbol{\Theta}\mathbf{(h(n))}$: 
                                
                                Menge aller Funktionen, die asymptotisch gleich schnell wachsen wie $h(n)$.
                            \end{itemize}
                            
                            \begin{subbox}{Small o-notation}
                                Seien $f$ und $g$ zwei Funktionen von $\N$ nach $\R^+$. 
                        
                                Falls $\lim_{n \to \infty} \frac{f(n)}{g(n)} = 0$, dann sagen wir, dass $g$ asymptotisch \textbf{schneller wächst} als $f$: 
                        
                                $$f(n) \in o(g(n))$$
                            \end{subbox}
                       
                            \myTitle{Bloomsches Speedup Theorem}
                            \begin{mainbox}{Satz 6.1}
                                Es \textbf{existiert} ein Entscheidungsproblem $(\Sigma_{\text{bool}}, L)$, 
                                so dass für jede MTM $A$, die $(\Sigma_{\text{bool}}, L)$ entscheidet, 
                                eine MTM $B$ existiert, die auch $(\Sigma_{\text{bool}}, L)$ entscheidet, und für die gilt
                                $$\text{Time}_B(n)\leq \log_2(\text{Time}_A(n))$$
                                für unendlich viele $n \in \N$.
                            \end{mainbox}
                            
                            I.e. es existieren Entscheidungsprobleme, die keinen optimalen Algorithmus haben.
                        
                            Deswegen fokussieren wir uns auf untere und obere Schranken der Komplexität eines Problemes und nicht auf die genaue Bestimmung davon.
                        
                            \myTitle{Komplexität eines Entscheidungsproblems $(\Sigma, L)$}
                            \begin{mainbox}{}
                                Sei $L$ eine Sprache. Sei $f, g: \N \to \R^+$.
                                \begin{itemize}[label=$\blacktriangleright$]
                                    
                                    \item $\O(g(n))$ ist eine \textbf{obere Schranke für die Zeitkomplexität von $L$}, falls eine MTM $A$ \textbf{existiert}, die $L$ entscheidet und Time$_A(n) \in \O(g(n))$.
                                    
                                    \item $\Omega(f(n))$ ist eine \textbf{untere Schranke für die Zeitkomplexität von $L$}, falls für \textbf{jede} MTM $B$ die $L$ entscheidet und Time$_B(n) \in \Omega(f(n))$.
                                    
                                    \item Eine MTM $C$ heisst \textbf{optimal für $L$}, falls Time$_C(n) \in \O(f(n))$ und $\Omega(f(n))$ eine untere Schranke für die Zeitkomplexität ist. 
                                \end{itemize}
                            \end{mainbox}
                            
                            Untere Schranke finden und beweisen: \textbf{schwierig}.
                        
                            Obere Schranke kann durch einen konkreten Algorithmus gezeigt werden.
                        \subsection{Komplexitätsklassen}
                            \begin{mainbox}{Klassen}
                                Für alle Funktionen $f, g : \N \to \R^+$ definieren wir
                                
                                \begin{align*}
                                    \textbf{TIME}\mathbf{(f)} &= \{L(B) \mid B \text{ ist eine MTM mit Time}_B(n) \in \O(f(n))\}\\
                                    \textbf{SPACE}\mathbf{(g)} &= \{L(A) \mid A \text{ ist eine MTM mit Space}_A(n) \in \O(g(n))\}\\
                                    \textbf{DLOG} &= \text{SPACE}(\log_2 n)\\
                                    \textbf{P} &= \bigcup_{c \in \N}\text{TIME}(n^c)\\
                                    \textbf{PSPACE} &= \bigcup_{c \in \N}\text{SPACE}(n^c)\\
                                    \textbf{EXPTIME} &= \bigcup_{d \in \N}\text{TIME}({2^n}^d)
                                \end{align*}
                            \end{mainbox}
                    
                        
                        \myTitle{Zeitkomplexität zu Platzkomplexität}
                            \begin{mainbox}{Lemma 6.3}
                                Für jede Funktion $t: \N \to \R^+$ gilt
                                $$\text{TIME}(t(n)) \subseteq \text{SPACE}(t(n))$$
                            \end{mainbox}
                            
                            \textbf{Beweisskizze:}
                        
                            In $\O(t(n))$ Schritten sind höchstens $\O(t(n))$ Felder beschreibbar.
                        
                            
                            \begin{mainbox}{Korollar 6.1}
                                $$\text{P} \subseteq \text{PSPACE}$$
                            \end{mainbox}
                        \subsection{Platz- \& Zeitkonstruierbarkeit}
                            \begin{mainbox}{}
                                EIne Funktion: $s: \N \to \N$ heisst \textbf{platzkonstruierbar}, falls eine $1$-Band-TM $M$ existiert, so dass 
                                \begin{enumerate}[label=(\roman*)]
                                    \item Space$_M(n) \leq s(n)$ für alle $n \in \N$ und 
                                    \item für jede Eingabe $0^n$, generiert $M$ das Wort $0^{s(n)}$ auf ihrem Arbeitsband und hält in $q_{\text{accept}}$.
                                \end{enumerate}
                            \end{mainbox}

                            \begin{mainbox}{}
                                EIne Funktion: $t: \N \to \N$ heisst \textbf{zeitkonstruierbar}, falls eine MTM $A$ existiert, so dass 
                                \begin{enumerate}[label=(\roman*)]
                                    \item Time$_A(n) \leq t(n)$ für alle $n \in \N$ und 
                                    \item für jede Eingabe $0^n$, generiert $A$ das Wort $0^{t(n)}$ auf dem ersten Arbeitsband und hält in $q_{\text{accept}}$.
                                \end{enumerate}
                            \end{mainbox}

                            \myTitle{Platzgarantien}
                            \begin{mainbox}{Lemma 6.4 (verständlicher formuliert)}
                                Sei $s: \N \to \N$ platzkonstruierbar.
                        
                                Für jede MTM $M$, für welche Space$_M(w) \leq s(|w|)$ nur für alle $w \in L(M)$ erfüllt, 
                                existiert eine äquivalente MTM $A$, welche dies für alle $w \in \Sigma^*$ erfüllt.
                            \end{mainbox}
                            
                            \textbf{Beweisskizze: }
                            
                            Erzeuge für jede Eingabe $x \in \Sigma^*$ zuerst $0^{s(|x|)}$ auf einem zusätzlichen Band und nutze das als Platzüberwachung. 
                            
                            
                            Wenn $A$ diesen Platz überschreiten will, wird die Simulation unterbrochen und die Eingabe verworfen.
                        
                        \myTitle{Zeitgarantien}
                            \begin{mainbox}{Lemma 6.5 (verständlicher formuliert)}
                                Sei $t: \N \to \N$ zeitkonstruierbar. 
                                
                                Zu jeder MTM $M$, welche Time$_M(w) \leq t(|w|)$ nur für alle $w \in L(M)$ erfüllt, 
                                
                                existiert eine äquivalente MTM $A$, welche zumindest Time$_A(w) \leq 2t(|w|) \in \O(t(|w|))$ für alle $w \in \Sigma^*$ erfüllt.
                        
                                $$\implies \text{Time}_A(n) \in \O(t(n))$$
                            \end{mainbox}
                            
                            \textbf{Beweisskizze: }
                            
                            Schreibe für jede Eingabe $x \in \Sigma^*$ $0^{t(|x|)}$ auf ein zusätzliches Arbeitsband und nutze dies zur Zeitzählung. 
                            
                            
                            Wenn $A$ mehr Schritte machen will, wird die Simulation abgebrochen und die Eingabe verworfen.
                        
                        \myTitle{Speicherplatzkomplexität zu Zeitkomplexität}
                            \begin{mainbox}{Satz 6.2}
                                Für jede Funktion $s$ mit $s(n) \geq \log_2(n)$ gilt:
                        
                            $$\textbf{SPACE}(s(n)) \subseteq \bigcup_{c \in \N} \textbf{TIME}(c^{s(n)})$$
                            \end{mainbox}
                            
                            \textbf{Beweis}
                        
                            Sei $L \in \textbf{SPACE}(s(n))$. Nach Lemma 6.1 existiert eine 1-Band-TM 
                            $M=(Q,\Sigma,\Gamma,\delta,q_0,q_{accept},q_{reject})$, die \textbf{immer hält}, 
                            so dass $L = L(M)$ und Space$_M(n) \leq d \cdot s(n)$ für $d \in \N$ gelten. 
                         
                            Für jede Konfiguration $C =(q,w,i,x,j)$ von $M$ definieren wir die 
                            \textbf{innere Konfiguration von $C$} als $$\text{In}(C) = (q,i,x,j).$$ 
                            
                            
                            Die innere Konfiguration enthält das Eingabewort $w$ nicht, da dies sich während einer Berechnung nicht ändert. 
                        
                            Sei InKonf$_M(n)$ die Menge aller möglichen inneren Konfigurationen auf Eingabewörtern der Länge $n$.
                        
                            Sei $X = |\text{InKonf}_M(n)|$ dessen Kardinalität.
                        
                            
                            Sei $D = C_1C_2...C_k$ eine endliche Berechnung von $M$ auf einem Wort $w, |w|=n$.
                        
                            
                            Wir zeigen per Widerspruch, dass $D$ maximal $X$ verschiedene Konfigurationen haben kann, i.e. $k \leq X$.
                        
                            
                            Nehmen wir zum Widerspruch an $k > X$.
                        
                            
                            Dann muss es in $D = C_1C_2...C_i...C_j...C_k$, zwei identische innere Konfigurationen In($C_i$) und In($C_j$) geben (für $i < j$).
                            
                            
                            Da $M$ deterministisch ist, sollte aber von $C_i = C_j$ aus immer die gleichen Berechnungsschritte ausgeführt werden.
                        
                             
                            Dann wäre aber $D$ eine unendliche Berechnung mit der Endlosschleife $C_iC_{i+1}...C_j$. \textbf{Widerspruch}, da $M$ immer hält.
                        
                            Eine beliebige endliche Berechnung $D$ von $M$ auf $w, |w| = n$, kann höchstens $X$ viele Zeitschritte (i.e. Konfigurationen) haben.
                        
                            Jetzt müssen wir noch $X = |\text{InKonf}_M(n)|$ abschätzen.
                            
                            Wir wissen folgendes
                            \begin{itemize}[label=$\blacktriangleright$]
                                
                                \item Es gibt $|Q|$ verschieden mögliche Zustände.
                                
                                \item Index des Eingabekopfes ist $0 \leq i \leq n+1$ (Eingabeband $\cent w \$$ mit $|w| = n$)
                                
                                \item Inhalt des Arbeitsbandes $x$ hat Länge: $|x| \leq \text{Space}_M(n) \leq d \dot s(n)$
                                
                                \item Index vom Kopf auf dem Arbeitsband: $0 \leq j \leq \text{Space}_M(n) \leq d \cdot s(n)$
                                
                                \item $x \in \Gamma^{|x|}$
                                
                                \item $n + 2 \leq 4^{\log_2n}\leq 4^{s(n)}$ für $n \geq 2$
                            \end{itemize}
                        
                    
                            Setzen wir alles zusammen:
                            \begin{align*}
                                |\text{InKonf}_M(n)| &\leq |Q| \cdot (n + 2) \cdot |\Gamma|^{\text{Space}_M(n)}\cdot \text{Space}_M(n)\\
                                                    &\leq (\max\{4, |Q|, |\Gamma|\})^{4d \cdot s(n)}\\
                                                    &\leq c^{s(n)}
                            \end{align*}
                            $\hfill\blacksquare$




\section{NP-Vollständigkeit}

\subsection{Verifikation}

	\begin{mainbox}{Verfizierer}
		Sei $L \subseteq \Sigma^*$ eine Sprache und sei $p: \N \to \N$ eine Funktion. 
		
		Ein Algorithmus $A$ (MTM) ist ein 
		\textbf{$\mathbf{p}$-Verfizierer für $\mathbf{L}$} mit $\mathbf{V(A) = L}$, falls 
		$A$ mit folgenden Eigenschaften auf allen Eingaben aus $\Sigma^* \times (\Sigma_{\text{bool}})^*$ arbeitet:
		\begin{enumerate}[label=(\roman*)]
			
			\item Time$_A(w, x) \leq p(|w|)$ für jede Eingabe $(w, x) \in \Sigma^* \times (\Sigma_{\text{bool}})^*$. 
			
			\item Für jedes $w \in L$ existiert ein $x \in (\Sigma_{\text{bool}})^*$, so dass $|x| \leq p(|w|)$ 
			und $(w, x) \in L(A)$. Das Wort $x$ nennt man einen \textbf{Beweis} oder einen \textbf{Zeugen} 
			der Behauptung $w \in L$.
			
			\item Für jedes $y \notin L$ gilt $(y, z) \notin L(A)$ für alle $z \in (\Sigma_{\text{bool}})^*$. 
		\end{enumerate}
	\end{mainbox}

	\begin{mainbox}{Polynomialzeitverifikation}
		Falls $p(n) \in \O(n^k)$ für ein $k \in \N$, so sagen wir, dass $A$ ein \textbf{Polynomialzeit-Verfizierer} ist.

		Wir definieren die \textbf{Klasse der in Polynomialzeit verifzierbaren Sprachen} als 
		$$\textbf{VP} = \{V(A) \mid A \text{ ist ein Polynomialzeit-Verfizierer}\}.$$
	\end{mainbox}

	\begin{mainbox}{Satz 6.8}
		VP = NP
	\end{mainbox}
	Die Klasse NP ist demnach die Klasse aller Sprachen $L$, 
	die für jedes $x \in L$ einen in $|x|$ polynomiell langen Beweis von ''$x \in L$'' haben, 
	welchen man deterministisch in polynomieller Zeit verifizieren bekann. 

	Dies können wir benutzen, um $L \in \text{NP}$ zu beweisen!

\subsection{P-Reduktion}
	\begin{mainbox}{}
		Seien $L_1 \subseteq \Sigma_1^*, L_2 \subseteq \Sigma_2^*$ zwei Sprachen. 
		Wir sagen, dass \textbf{$\mathbf{L_1}$ polynomiell auf $\mathbf{L_2}$ reduzierbar 
		ist, $\mathbf{L_1 \leq_{p} L_2}$}, falls eine polynomieller Algorithmus $A$ existiert, 
		der für jedes Wort $x \in \Sigma_1^*$ ein Wort $A(x) \in \Sigma_2^*$ berechnet, so dass
		$$x \in L_1 \iff A(x) \in L_2$$
		$A$ wird eine \textbf{polynomielle Reduktion} von $L_1$ auf $L_2$ genannt. 
	\end{mainbox}
	\textbf{Bemerkung} 
    
    Analog zur EE-Reduktion, nur das $A$ jetzt noch polynomiell laufen muss.

\myTitle{Begrifflichkeiten}
	\begin{mainbox}{}
		Eine Sprache $L$ ist \textbf{NP-schwer}, falls für alle Sprachen $L' \in $NP gilt $L' \leq_p L$.

		Eine Sprache $L$ ist \textbf{NP-vollständig}, falls
		\begin{enumerate}[label=(\roman*)]
			\item $L \in $NP und
			\item $L$ ist NP-schwer.
		\end{enumerate}
	\end{mainbox}
	\begin{mainbox}{Lemma 6.7}
		Falls $L \in P$ und $L$ ist NP-schwer, dann gilt P = NP.
	\end{mainbox}


\myTitle{Satz von Cook}

	Wir haben 
	$$\text{SAT} = \{x \in (\Sigma_{\text{logic}})^* \mid x \text{ kodiert eine erfüllbare Formel in KNF}\}$$

	\begin{mainbox}{Satz 6.9}
		SAT ist NP-vollständig.
	\end{mainbox}
	Da $$L_1 \leq_{p} L_2 \implies (L_2 \in \text{P} \implies L_1 \in \text{P})$$
	können wir mit diesem Resultat die NP-Schwere anderer Probleme einfacher beweisen.


\subsection{Klassische Probleme}
	\begin{align*}
		\text{SAT} &= \{\phi \mid \phi \text{ ist eine erfüllbare Formel in KNF}\}\\
		\text{CLIQUE} &= \{(G, k) \mid G \text{ ist ein ungerichteter Graph, der eine $k$-Clique enthält}\}\\
		\text{VC} &= \{(G, k) \mid G \text{ ist ein ungerichteter Graph mit einer Knotenüberdeckung}\\ 
		 & \hspace{2cm}\text{(vertex cover) der Mächtigkeit höchstens }k\}
	\end{align*}
	
	\textbf{Higher-Level of Abstraction} 

	Wir müssen uns nicht mehr überlegen, wie die Probleminstanzen als endliche Wörter kodiert sind!

	
	Das heisst auch, dass ihr nicht mehr explizit auf falsche Form überprüfen müsst.

	Ihr könnt annehmen, dass die Eingabe jeweils schon eine wohlgeformte Instanz des Problems ist.


\subsection{Aufgabe 6.22.a}
	Beweise 
	$$\text{VC} \leq_p \text{CLIQUE}$$
	Zur Erinnerung:
	\begin{align*}
		\text{CLIQUE} &= \{(G, k) \mid G \text{ ist ein ungerichteter Graph, der eine $k$-Clique enthält}\}\\
		\text{VC} &= \{(G, k) \mid G \text{ ist ein ungerichteter Graph mit einer Knotenüberdeckung}\\ 
		 & \hspace{2cm}\text{(vertex cover) der Mächtigkeit höchstens }k\}
	\end{align*}
	Ein VC ist eine Knotenmenge $C \subseteq V$, so dass 
	$$\forall \{u, v\} \in E. v \in C \lor u \in C.$$

    Dies kann ein bisschen non-intuitiv sein, da die Knotenmenge eigentlich alle Kanten überdecken muss:)

	Wir beschreiben einen polynomiellen Algorithmus $A$:

	\textbf{Eingabe} $(G = (V, E), k)$ für VC
	\begin{enumerate}[label=\arabic*.]
		\item Findet $\overline{G} = (V, \overline{E})$ mit $\overline{E} = \{\{u, v\} \mid u, v \in V, u \neq v, \{u, v\} \notin E\}$
		\item Gibt $(\overline{G}, |V| - k)$ aus.
	\end{enumerate}
	Es sollte klar sein, dass $A$ polynomiell läuft.

	\textbf{Korrektheit}

	Wir beweisen nun 
	$$S \subseteq V \text{ ist ein Vertex Cover von }G \iff V\setminus S \text{ ist eine Clique von } \overline{G}$$

	$\mathbf{(\implies):}$

	Sei $S \subseteq V$ ein Vertex Cover von $G$. 
	
	
	$\implies$ Per Definition gilt für jede Kante $\{u, v\} \in E$ mindestens $u \in S$ oder $v \in S$.
		
	
	$\implies$ Also existiert keine Kante $\{u, v\} \in E$ mit $u, v \in V\setminus S$.

	
	$\implies$ Deshalb gilt für alle $u, v \in V \setminus S, u \neq v$, dass $\{u, v\} \in \overline{E}$. 
		
	
	$\implies$ $V \setminus S$ ist eine Clique in $\overline{G}$.


	$\mathbf{(\impliedby):}$

	Sei $V\setminus S$ eine Clique in $\overline{G}$. 
	
	
	$\implies$ Per Definition gilt für alle Knotenpaare $u, v \in V\setminus S, u \neq v$ jeweils $\{u, v\} \in \overline{E}$.
		
	
	$\implies$ Also existiert keine Kante $\{u, v\} \in E$ mit $u, v \in V\setminus S$.

	
	$\implies$ Deshalb gilt für alle $\{u, v\} \in E$, dass $u \in S$ oder $v \in S$. 
		
	
	$\implies$ $S$ ist ein Vertex Cover in $G$.
	
	Mit der Aussage 
	$$S \subseteq V \text{ ist ein Vertex Cover von }G \iff V\setminus S \text{ ist eine Clique von } \overline{G} \qquad (1)$$
	können wir nun die Korrektheit beweisen.
	
	\begin{align*}
		(G, k) \in \text{VC} &\iff \exists S \subseteq V: S \text{ ist ein VC von } G \text{ und } |S| \leq k\\
		&\iff V\setminus S \text{ ist eine Clique von } \overline{G} \text{ und } |V\setminus S| \geq |V| - k\\
		&\iff (\overline{G}, |V| - k) \in \text{CLIQUE}\\
		&\iff A((G, k)) \in \text{CLIQUE}
	\end{align*}
	$\hfill\blacksquare$


\section{How To P-Reduktion}

\subsection{PROBLEM $\in $ NP}
	Beschreibung eine NTM $M$, die PROBLEM erkennt mit folgender Form:
	
	\begin{enumerate}[label=\arabic*.]
		\item $M$ errät für eine Eingabe $x$ nicht deterministisch ein Zertifikat/Beweis (z.B. eine erfüllende Belegung für SAT oder eine Clique für CLIQUE). 
		
		\item $M$ verfiziert das Zertifikat deterministisch in Polynomialzeit.
	\end{enumerate}
	
	\textbf{Korrektheit}
	
	$x \in \text{PROBLEM}$ $\iff$ Es existiert ein solches Zertifikat $\iff$ Es existiert eine akzept. Berechnung von $M$ auf $x$ $\iff$ $x \in L(M)$ 

\subsection{PROBLEM ist NP-schwer}
	Beweise $$\text{OTHERPROBLEM} \leq_p \text{PROBLEM}$$
	für ein anderes OTHERPROBLEM, dass NP-schwer ist (in der Vorlesung gezeigt oder ähnl.).

	\textit{Alternativ könnte man auch etwas wie den Beweis vom Satz von Cook machen}. \textbf{(Don't)}

\subsection{PROBLEM ist NP-Vollständig}
	Zeige 
	\begin{enumerate}[label=\arabic*]
		\item PROBLEM $\in $ NP
		\item PROBLEM ist NP-schwer
	\end{enumerate}

	\subsection{OTHERPROBLEM $\leq_p$ PROBLEM}
	\begin{enumerate}[label=\arabic*.]
		
		\item \textbf{Beschreibung} eines Algorithmus $A$, so dass 
		$$x \in \text{OTHERPROBLEM} \iff A(x) \in \text{PROBLEM}$$
		
		\item \textbf{Korrektsheitsbeweis} von 
		$$x \in \text{OTHERPROBLEM} \iff A(x) \in \text{PROBLEM}$$
		(nichttrivial)
		
		\item \textbf{Polynomialzeit} von $A$ beweisen/argumentieren. Meistens recht einfach. 
	\end{enumerate}

\subsection{Idee finden für Polynomialzeitreduktion}
	Grundsätzlich 2 Typen von Problemen/Sprachen:
	\begin{enumerate}[label=\arabic*]
		\item Satisifiability: Logische Formeln (deren Erfüllbarkeit). Beispielsweise SAT und 3SAT, 4SAT...
		\item Graphenprobleme: Eigenschaften von Graphen. Beispielsweise CLIQUE, VC, DS etc.
	\end{enumerate}
	% Das SCP würde ich vom Typ her, zu den Graphenproblemen zählen.


\subsubsection{Satisfiablity zu Satisfiability - Idee}
	Meist müssen wir einzelne Klauseln umschreiben. Veränderung der Anzahl Literale.
	\begin{itemize}[label=-]
		\item \textbf{Literale verringern.} (Für allg. siehe im Buch, Lemma 6.11)
			
		Beispiel: 6SAT $\leq_p$ 4SAT
			$$(x_1 \lor x_2 \lor x_3 \lor x_4 \lor x_5) \mapsto  (y_1 \lor x_1 \lor x_2 \lor x_3) \land (\overline{y}_1 \lor x_4 \lor x_5)$$
			$$(x_1 \lor x_2 \lor x_3 \lor x_4 \lor x_5 \lor x_6) \mapsto  (y_1 \lor x_1 \lor x_2 \lor x_3) \land (\overline{y}_1 \lor x_4 \lor x_5 \lor x_6)$$
			Beispiel: E8SAT $\leq_p$ E4SAT
			
			\begin{align*}
				(x_1 \lor x_2 \lor x_3 \lor x_4 \lor x_5 \lor x_6 \lor x_7 \lor x_8) \mapsto  &(y_1 \lor x_1 \lor x_2 \lor x_3) \land (\overline{y}_1 \lor x_4 \lor x_5 \lor y_2) \\
				&\land (\overline{y}_2 \lor x_6 \lor x_7 \lor x_8)
			\end{align*}

	\item \textbf{Mehr Literale.} 
	
			Beispiel: 5SAT $\leq_p$ E5SAT
			$$(x_1 \lor x_2 \lor x_3 \lor x_4 \lor x_5) \mapsto  (x_1 \lor x_2 \lor x_3 \lor x_4 \lor x_5)$$
			$$(x_1 \lor x_2 \lor x_3 \lor x_4) \mapsto  (x_1 \lor x_2 \lor x_3 \lor x_4 \lor y_1) \land (x_1 \lor x_2 \lor x_3 \lor x_4  \lor \overline{y}_1)$$
			
			\begin{align*}
				(x_1 \lor x_2 \lor x_3) \mapsto &(x_1 \lor x_2 \lor x_3 \lor y_1 \lor y_2) \\
			&\land (x_1 \lor x_2 \lor x_3 \lor \overline{y}_1 \lor y_2) \\
			&\land (x_1 \lor x_2 \lor x_3 \lor y_1 \lor \overline{y}_2) \\
			&\land (x_1 \lor x_2 \lor x_3 \lor \overline{y}_1 \lor \overline{y}_2)
			\end{align*}
			etc.

		\item \textbf{Mehr erfüllende Belegungen.}
		
		Füge Klausel hinzu. I.e.

		$$\phi \mapsto \phi \land (y_1 \lor y_2)$$
		verdreifacht die Anzahl der erfüllenden Belegungen.
	\end{itemize}


\subsubsection{Satisfiability zu Satisfiability Reduktion - OTHERPROBLEM $\leq_p$ PROBLEM}
	\textbf{Schema}
	
	Sei $F = F_1 \land ... \land F_m$ eine KNF Formel vom Typ OTHERPROBLEM
	
	
	Eingabe für $A$: $F$
	\begin{itemize}[label=-]
		\item $A$ konstruiert $B = B_1 \land ... \land B_m$ mit einem der Tricks von oben.
	\end{itemize} 

	
	\textbf{Korrektheit}
	
	
	\begin{align*}
		F \in \text{OTHERPROBLEM} &\iff F \text{ erfüllbar}\\
		&\iff \text{ Es existiert eine Belegung } \varphi: \varphi(F) = 1\\
		&\iff \exists \varphi: \varphi(F_i) = 1 \forall i \in \{1, ..., m\}\\
		&\text{  ...} \text{ Argumentation für beliebige Klausel }\\
		&\iff \exists \varphi': \varphi'(B_i) = 1 \forall i \in \{1, ..., m\}\\
		&\iff B \text{ erfüllbar}\\
		&\iff B \in \text{PROBLEM}
	\end{align*}


\subsubsection{Graphproblem zu Graphproblem - Reduktion}

	\textbf{Patterns}
	\begin{enumerate}[label=\arabic*.]
		
		\item Aus $G = (V, E)$ Komplementgraph $\overline{G}$ bilden. I.e. $\overline{G} = (V, \overline{E})$ mit 
		$$\overline{E} = \{\{u, v\} \mid u, v \in V, u \neq v, \{u, v\} \notin E\}$$
		
		\item Eingabetupel $(G, k)$ zu $(G, n - k)$ abbilden ($n = |V|$).
		
		\item Beides davon (siehe CLIQUE zu VC).
		
		\item Ersetzen einer Kante durch anderes Konstrukt 
		\begin{itemize}[label=-]
			\item 2 Kanten mit Knoten dazwischen
			\item Knoten hinzufügen für jede Kante und mit beiden Eckpunkten verbinden
		\end{itemize}
	\end{enumerate}

\subsubsection{Satisfiability zu Graphproblem}
	Beispiel: Lemma 6.9 SAT $\leq_p$ CLIQUE

	Denkt über die Reduktion vom Satisfiability Problem zu SAT und von CLIQUE zum Graphproblem.

	Versucht diese Abbildungen zu verknüpfen.


\subsubsection{Graphenproblem zu Satisfiability}
	Vielleicht \textbf{Satz von Cook} verwenden?

	Scheint sehr komplex eine konkrete Reduktion zu machen.


	\myTitle{PROBLEM $\leq_p$ SAT}
	
	\textbf{Generelle Idee}

	\begin{itemize}[label= -]
		
		\item Denke über Zertifikate für PROBLEM nach. Welche Bestandteile haben sie?
		
		Beispielsweise im Fall von Clique ist das Zertifikat eine Knotenmenge (alle untereinander verbunden).

		
		\item Kreiert eine Variablenmenge mit einer Variable pro mögliches Element für das Zertifikat. 
		
		I.e. im Fall von CLIQUE eine Variable pro Knoten

		
		\item I.e. Wir werden dann für eine Belegung der Formel wissen welche Knoten im Zertifikat enthalten sind.
		
		\item Baue die Formel, die die Bedingungen kodiert, damit genau dann erfüllt sein kann, falls es ein Zertifikat gibt.
	\end{itemize}

            % \section{How To Reduktion}
            
            %     \subsection{$L \in \Lr$ }

            %         Wir kennen zwei Methoden um dies zu beweisen:
            %         \begin{itemize}[label=-]
            %             \item Wir finden eine Sprache $L' \in \L_\text{R}$ und zeigen $L \leq_{\text{R}} L'$. (Meistens ein wenig umständlich)
            %             \item Direkter Beweis:  Eine TM (bzw. ein Algorithmus) $A$ beschreiben, so dass $L(A) = L$ und $A$ immer terminiert.
            %         \end{itemize}
            
            
            
            %     \subsection{$L \notin \Lr$}

            %         Wir kennen hier auch 3 Arten:
            %         \begin{itemize}[label=-]
            %             \item Folgt sofort aus $L \notin \L_{\text{RE}}$, da $\L_{\text{R}} \subset \L_{\text{RE}}$.
            %             \item Wir wählen eine Sprache $L'$, so dass $L' \notin \L_{\text{R}}$ und beweisen $L' \leq_{\text{R/EE}} L$.
                        
            %                 Geeignete Sprachen als $L'$ sind: $L_{empty}^\complement, L_{diag}^\complement, L_\text{H}, L_\text{U}, L_{\text{H}, \lambda}$. (Alle im Buch bewiesen)
            %             \item Satz von Rice 
            %         \end{itemize}
            
            
            % \subsection{Anwendung von Satz von Rice}

            %     Für den \textbf{Satz von Rice}:
            %     \begin{itemize}[label=-]
            %         \item Wir können mit diesem Satz nur $L \notin \L_{\text{R}}$ beweisen!
            %         \item Wir haben folgende Bedingungen:
            %         \begin{enumerate}[label=\roman*.]
            %             \item $L \subseteq \text{KodTM}$
            %             \item $\exists$ TM $M$: Kod$(M) \in L$
            %             \item $\exists$ TM $M$: Kod$(M) \notin L$
            %             \item $\forall$ TM $M_1, M_2$: $L(M_1) = L(M_2) \implies \left(\text{Kod}(M_1) \in L \iff \text{Kod}(M_2) \in L\right)$
            %         \end{enumerate}
            %         Für den letzten Punkt (4) muss man überprüfen, ob in der Definition von $L = \{\text{Kod}(M) \mid M \text{ ist TM und ...}\}$ überall nur $L(M)$ vorkommt und nirgends $M$ direkt. Beziehungsweise reicht es, wenn man die Bedingung so umschreiben kann, dass sie nur noch durch $L(M)$ beschrieben ist.
            %     \end{itemize}
            
            
            
            %     \subsection{$L \in \L_{\text{RE}}$}

            %         Wir beschreiben eine TM $M$ mit $L(M) = L$, die nicht immer halten muss. 
                    
            %         Meistens muss die TM eine Eigenschaft, für alle möglichen Wörter prüfen. (Bsp: $\text{Kod}(M_1) \in L_\text{H}^\complement$: Wir gehen alle Wörter durch, um dasjenige zu finden, für das $M_1$ hält.)
                    
            %         Wir verwenden oft einen von den folgenden 2 Tricks, um dies zu tun:
            %         \begin{itemize}
            %             \item Da es für jede NTM $M'$, eine TM $M$ gibt, so dass $L(M') = L(M)$, können wir eine solche definieren, für die $L(M') = L$ gilt.
            %             \item Die andere Variante, ist die parallele Simulation von Wörtern, bei dem man das Diagonalisierungsverfahren aus dem Buch verwendet. (Bsp: Beweis $L_{\text{empty}} \in \L_{\text{RE}}$, S. 156 Buch)
            %         \end{itemize}
            
            
            
            %     \subsection{$L \notin \L_{\text{RE}}$}

            %         Hier haben wir 2 mögliche (offizielle) Methoden:
            %         \begin{itemize}[label=-]
            %             \item Diagonalisierungsargument mit Widerspruch, wie beim Beweis von $L_{\text{diag}} \notin \L_{\text{RE}}$.
            %             \item Widerspruchsbeweis mit der Aussage $L \in \L_{\text{RE}} \land L^\complement \in \L_{\text{RE}} \implies L \in \L_{\text{R}}$.
            %         \end{itemize}
            %         Inoffiziell könnten wir auch die EE-Reduktion verwenden, wird aber weder in der Vorlesung noch im Buch erwähnt.
            
            %     \subsection{EE- und R-Reduktionen: Tipps und Tricks}

            %         \begin{itemize}[label=-]
            %             \item Die vorgeschaltete TM $A$ muss immer terminieren! I.e. sie muss ein Algorithmus sein.
                        
            %             \item Die Eingabe sollte immer zuerst auf die Richtige Form überprüft werden!
                        
            %             Auch im Korrektsheitsbeweis, sollte dieser Fall als erstes abgehandelt werden.
            %             \item Für Korrektheit müssen wir immer $x \in L_1 \iff A(x) \in L_2$ beweisen.
                        
            %             \item Wir verwenden meistens folgende 2 Tricks:
            %             \begin{enumerate}[label=\roman*.]
            %                 \item Transitionen nach $q_{accept}$ oder $ q_{reject}$ umleiten nach $q_{reject}$/$q_{accept}$ oder einer \textbf{Endlosschleife}. 
            %                 \item TM $M'$ konstruieren, die ihre Eingabe ignoriert und immer dasselbe tut (z.B. eine TM dessen Kodierung gegeben ist, auf ein fixes Wort simuliern).
            %             \end{enumerate}
                        
            %             \item Die Kodierung einer TM generieren, dessen Sprache gewisse Eigenschaften hat(z.B. sie akzeptiert alle Eingaben, läuft immer unendlich etc.)
            %         \end{itemize}
    




    % --------------------------------------------------------------------------------------------
    % Beweise

%     \section{Beweisesammlung}

%     \subsubsection*{Lemma 5.4}
%     Sei $\Sigma$ ein Alphabet. Für jede Sprache $L \subseteq \Sigma^*$ gilt:
    
%     $$L \leq_\text{R} L^\complement \text{ und } L^\complement \leq_\text{R} L$$

%     \textbf{Beweis: }
%     Es reicht $L^\complement \leq_\text{R} L$ zu zeigen, da $(L^\complement)^\complement = L$ und somit dann $(L^\complement)^\complement = L \leq_\text{R} L^\complement$.

%     Sei $M'$ ein Algorithmus für $L$, der immer hält ($L \in \L_\text{R}$). Dann beschreiben wir einen Algorithmus $B$, der $L^\complement$ entscheidet. 
    
%     $B$ übernimmt die Eingaben und gibt sie an $M'$ weiter und invertiert dann die Entscheidung von $M'$. Weil $M'$ immer hält, hält auch $B$ immer und wir haben offensichtlich $L(B) = L$.

%     \hspace*{0pt}\hfill$\blacksquare$

%     \subsubsection*{Korollar 5.2 (bzw. Anwendung von Lemma 5.4)}
%     $(L_\text{diag})^\complement \notin \L_\text{R}$.
    
%     \textbf{Beweis:} 
    
%     Aus Lemma 5.4 haben wir $L_\text{diag} \leq_\text{R} (L_\text{diag})^\complement$. Daraus folgt $L_\text{diag} \notin \Lr \implies (L_\text{diag})^\complement \notin \Lr$.
%     Da $L_\text{diag} \notin \Lre$ gilt auch $L_\text{diag} \notin \Lr$. 
    
%     Folglich gilt $(L_\text{diag})^\complement \notin \Lr$.

%     \hspace*{0pt}\hfill$\blacksquare$

    
   
%     \subsubsection*{Lemma 5.8}
%     $L_{\text{H}, \lambda} \notin \Lr$.

%     \textbf{Beweis: }

%     Wir zeigen $L_\text{H} \leq_\text{EE} L_{\text{H}, \lambda}$. Wir beschreiben einen Algorithmus $B$, so dass $x \in L_\text{H} \iff B(x) \in L_{\text{H}, \lambda}$.

%     Für jede Eingabe arbeitet $B$ wie folgt:
%     \begin{itemize}
%         \item Falls $x$ von der falschen Form, dann $B(x) = M_{inf}$, wobei $M_{inf}$ unabhängig von der Eingabe immer unendlich läuft.
%         \item Sonst $x = \text{Kod}(M)\#w$: Dann $B(x) = M'$, wobei $M'$ die Eingabe ignoriert und immer $M$ auf $w$ simuliert.
%     \end{itemize}

%     Wir sehen, dass $M'$ genau dann auf $\lambda$ hält, wenn $x \in L_{\text{H}}$.

%     Daraus folgt $x \in L_\text{H} \iff B(x) \in L_{\text{H}, \lambda}$.

%     \hspace*{0pt}\hfill$\blacksquare$

%     \subsection*{Kapitel 6}
    
%     \subsubsection*{Lemma 6.1}
%     Sei $k$ eine positive ganze Zahl. Für jede $k$-Band Turingmaschine $A$, die immer hält, existiert eine äquivalente $1$-Band-TM $B$, so dass
%     $$\text{Space}_B(n) \leq \text{Space}_A(n)$$

%     \textbf{Beweisskizze: }

%     Gleiche Konstruktion wie in Lemma 4.2. Wir können leicht sehen, dass $B$ genau so viele Felder braucht, wie $A$.


%     \subsubsection*{Lemma 6.2}
%     Zu jeder MTM $A$ existiert eine äquivalente MTM $B$ mit 
%     $$\text{Space}_B(n) \leq \frac{\text{Space}_A(n)}{2}+2$$

%     \textbf{Beweisskizze: }

%     Wir fassen jeweils 2 Felder von $A$ zu einem Feld in $B$ zusammen. $\Gamma_B = \Gamma_A \times \Gamma_A$. Wir addieren $1$ für das $\cent$ am linken Rand und $1$ für das Aufrunden im Fall von ungerader Länge.

%     \subsubsection*{Lemma 6.3}
%     TIME($t$) $\subseteq$ SPACE($t$)

%     \textbf{Beweisskizze: }
%     In $t$ Schritten sind höchstens $t$ Felder beschreibbar.

%     \subsubsection*{Lemma 6.4}
%     Sei $S$ platzkonstruierbar. Für jede MTM $M$, für welche Space$_M(w) \leq s(|w|)$ nur für alle $w \in L(M)$ erfüllt, existiert eine äquivalente MTM $M'$, welche dies für alle $w \in \Sigma^*$ erfüllt.

%     \textbf{Beweisskizze: }
%     Erzeuge für jede Eingabe $x \in \Sigma^*$ zuerst $0^{s(|x|)}$ auf einem zusätzlichen Band und nutze das als Platzüberwachung. Wenn $M'$ diesen Platz überschreiten will, wird die Simulation unterbrochen und die Eingabe verworfen.

%     \subsubsection*{Lemma 6.5}
%     Sei $t$ zeitkonstruierbar. Zu jeder MTM, welche Time$_M(w) \leq t(|w|)$ nur für alle $w \in L(M)$ erfüllt, existiert eine äquivalente MTM $M'$, welche zumindest Time$_M(w) \leq 2t(|w|) \in \O(t(|w|))$ für alle $w \in \Sigma^*$ erfüllt.

%     \textbf{Beweisskizze: }
%     Schreibe für jede Eingabe $x \in \Sigma^*$ $0^{t(|x|)}$ auf ein zusätzliches Arbeitsband und nutze dies zur Zeitzählung. Wenn $M'$ mehr Schritte machen will, wird die Simulation abgebrochen und die Eingabe verworfen.

%     \subsubsection*{Satz 6.2}
%     Für jede Funktion $s$ mit $s(n) \geq \log_2(n)$ gilt:

%     $$\textbf{SPACE}(s(n)) \subseteq \bigcup_{c \in \N} \textbf{TIME}(c^{s(n)})$$

%     \textbf{Beweis: } 

%     Sei $L \in \textbf{SPACE}(s(n))$. Nach Lemma 6.1 existiert eine 1-Band-TM $M=(Q,\Sigma,\Gamma,\delta,q_0,q_{accept},q_{reject})$, die \textbf{immer hält}, so dass $L = L(M)$ und Space$_M(n) \leq d \cdot s(n)$ für $d \in \N$ gelten. Für jede Konfiguration $C =(q,w,i,x,j)$ von $M$ definieren wir die \textbf{innere Konfiguration von $C$} als $$\text{In}(C) = (q,i,x,j).$$ 
%     Die innere Konfiguration enthält das Eingabewort $w$ nicht, da dies sich während einer Berechnung nicht ändert. 

%     Wir betrachten die Menge aller inneren Konfigurationen , dass bei einer \textbf{deterministischen} TM jede Berechnung $D = C_1,C_2,C_3, ...$ von $M$ auf einem Wort $w$ mit $|w| = n$, die länger als 





% %-----------------------------------------------------------------



% %------------------------------------------------------------------

%     \section{EE-Reduktionen und R-Reduktionen -- Komplexitätsbeweise}
%     \textit{Mit Inspiration von der Zsf. von Fabian Frei}

%     Generelle Bemerkungen:
%     \begin{itemize}
%         \item $L$ rekursiv (entscheidbar) $\iff$ $L \in \L_{\text{R}}$
%         \item $L$ rekursiv aufzählbar $\iff$ $L \in \L_{\text{RE}}$
%         \item "Algorithmus" ist ein anderes Wort für eine Turingmaschine, die \textbf{immer} terminiert.
%     \end{itemize}
%     \subsection{$L \in \L_\text{R}$ }
%     Wir kennen zwei Methoden um dies zu beweisen:
%     \begin{itemize}
%         \item Wir finden eine Sprache $L' \in \L_\text{R}$ und zeigen $L \leq_{\text{R}} L'$. (Meistens ein wenig umständlich)
%         \item Direkter Beweis:  Eine TM (bzw. ein Algorithmus) $A$ beschreiben, so dass $L(A) = L$ und $A$ immer terminiert.
%     \end{itemize}
%     \subsection{$L \notin \L_{\text{R}}$}
%     Wir kennen hier auch 3 Arten:
%     \begin{itemize}
%         \item Folgt sofort aus $L \notin \L_{\text{RE}}$, da $\L_{\text{R}} \subset \L_{\text{RE}}$.
%         \item Wir wählen eine Sprache $L'$, so dass $L' \notin \L_{\text{R}}$ und beweisen $L' \leq_{\text{R/EE}} L$.
        
%             Geeignete Sprachen als $L'$ sind: $L_{empty}^\complement, L_{diag}^\complement, L_\text{H}, L_\text{U}, L_{\text{H}, \lambda}$. (Alle im Buch bewiesen)
%         \item Satz von Rice 
%     \end{itemize}

%     Für den \textbf{Satz von Rice}:
%     \begin{itemize}
%         \item Wir können mit diesem Satz nur $L \notin \L_{\text{R}}$ beweisen!
%         \item Wir haben folgende Bedingungen:
%         \begin{enumerate}
%             \item $L \subseteq \text{KodTM}$
%             \item $\exists$ TM $M$: Kod$(M) \in L$
%             \item $\exists$ TM $M$: Kod$(M) \notin L$
%             \item $\forall$ TM $M_1, M_2$: $L(M_1) = L(M_2) \implies \left(\text{Kod}(M_1) \in L \iff \text{Kod}(M_2) \in L\right)$
%         \end{enumerate}
%         Für den letzten Punkt (4) muss man überprüfen, ob in der Definition von $L = \{\text{Kod}(M) \mid M \text{ ist TM und ...}\}$ überall nur $L(M)$ vorkommt und nirgends $M$ direkt. Beziehungsweise reicht es, wenn man die Bedingung so umschreiben kann, dass sie nur noch durch $L(M)$ beschrieben ist.
%     \end{itemize}
    
    
%     \subsection{$L \in \L_{\text{RE}}$}
%     Wir beschreiben eine TM $M$ mit $L(M) = L$, die nicht immer halten muss. 
    
%     Meistens muss die TM eine Eigenschaft, für alle möglichen Wörter prüfen. (Bsp: $\text{Kod}(M_1) \in L_\text{H}^\complement$: Wir gehen alle Wörter durch, um dasjenige zu finden, für das $M_1$ hält.)
    
%     Wir verwenden oft einen von den folgenden 2 Tricks, um dies zu tun:
%     \begin{itemize}
%         \item Da es für jede NTM $M'$, eine TM $M$ gibt, so dass $L(M') = L(M)$, können wir eine solche definieren, für die $L(M') = L$ gilt.
%         \item Die andere Variante, ist die parallele Simulation von Wörtern, bei dem man das Diagonalisierungsverfahren aus dem Buch verwendet. (Bsp: Beweis $L_{\text{empty}} \in \L_{\text{RE}}$, S. 156 Buch)
%     \end{itemize}

%     \subsection{$L \notin \L_{\text{RE}}$}
%     Hier haben wir 2 mögliche (offizielle) Methoden:
%     \begin{itemize}
%         \item Diagonalisierungsargument mit Widerspruch, wie beim Beweis von $L_{\text{diag}} \notin \L_{\text{RE}}$.
%         \item Widerspruchsbeweis mit der Aussage $L \in \L_{\text{RE}} \land L^\complement \in \L_{\text{RE}} \implies L \in \L_{\text{R}}$.
%     \end{itemize}
%     Inoffiziell könnten wir auch die EE-Reduktion verwenden, wird aber weder in der Vorlesung noch im Buch erwähnt.

%     \subsection{EE- und R-Reduktionen: Tipps und Tricks}
%     \begin{itemize}
%         \item Die vorgeschaltete TM $A$ muss immer terminieren! I.e. sie muss ein Algorithmus sein.
%         \item Die Eingabe sollte immer zuerst auf die Richtige Form überprüft werden!
        
%         Auch im Korrektsheitsbeweis, sollte dieser Fall als erstes abgehandelt werden.
%         \item Für Korrektheit müssen wir immer $x \in L_1 \iff A(x) \in L_2$ beweisen.
%         \item Wir verwenden meistens folgende 2 Tricks:
%         \begin{enumerate}
%             \item Transitionen nach $q_{accept}$ oder $ q_{reject}$ umleiten nach $q_{reject}$/$q_{accept}$ oder einer \textbf{Endlosschleife}. 
%             \item TM $M'$ konstruieren, die ihre Eingabe ignoriert und immer dasselbe tut (z.B. eine TM dessen Kodierung gegeben ist, auf ein fixes Wort simuliern).
%         \end{enumerate}
%         \item Die Kodierung einer TM generieren, dessen Sprache gewisse Eigenschaften hat(z.B. sie akzeptiert alle Eingaben, läuft immer unendlich etc.)
%     \end{itemize}

    



%     \section{Polynomialzeitreduktionen}

%     Typische Aufgabe: $L$ ist NP-Vollständig. Dann müssen wir (i) $L$ in NP und (ii) $L$ ist NP-schwer zeigen.

%     \begin{enumerate}[label = (\roman*)]
%         \item Wir beschreiben eine NTM $M$, so dass $L(M) = L$. $M$ errät (nichtdeterministisch) ein Zertifikat und verfiziert dies (deterministisch) in Polynomialzeit.
%         $M$ akzeptiert, wenn die Verfikation erfolgreich ist.

%         $M$ akzeptiert $\iff$ $M$ hat eine akzeptierende Berechnung
%         \item \begin{itemize}
%              \item Wir nehmen eine Sprache $L'$ die NP-Schwer ist und zeigen $L' \leq_{p} L$.
             
%                 \textbf{Beweisidee: }
                
%                 Wir zeigen eine Reduktion indem wir einen Polynomialzeit Algorithmus $A$ beschreiben, so dass $x \in L \iff A(x) \in L'$.
%                 Wir müssen also folgende 2 Punkte für $A$ beweisen:
%                 \begin{itemize}
%                     \item $x \in L \iff A(x) \in L'$ (meist recht komplex, beide Richtungen einzeln beweisen)
%                     \item $A$ läuft in Polynomialzeit (meist trivial, es reicht eine High-Level Begründung zu geben)
%                 \end{itemize}


%              \item Wir könnten es auch direkt beweisen(wie Beweis vom Satz von Cook). Dies ist aber meist zu komplex.
%         \end{itemize}
%     \end{enumerate}

    




%     \section{Grammatiken}



%     \textbf{Beispiel 10.6}

%     Sei $L = \{a^nb^nc^n \mid n \in \N\}$
   
%     Beweis durch Widerspruch:

%     Sei $L$ kontextfrei. Dann gilt das Pumping Lemma für kontextfreie Sprachen.

%     Sei $n_L$  die Konstante aus dem Pumping Lemma.

%     Dann wählen wir $z = a^{n_L}b^{n_L}c^{n_L}, |z| \geq n_L, z \in L$.

%     Dann gilt für jede Partition $z = uvwxy$ mit (i) $|vx| \geq 1$ und (ii) $|vwx| \leq n_L$, auch (iii) $\{uv^iwx^iy \mid i \in \N\}$.
\end{document}
